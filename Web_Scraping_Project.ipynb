{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecbe2d8c-ef4d-4fda-8700-2a39b560e1b6",
   "metadata": {},
   "source": [
    "This Python script scrapes complaint data from the Better Business Bureau website for Securus Technologies, LLC, one of the largest private vendors in U.S. prison communications. Using Selenium and BeautifulSoup, it automates page navigation, expands hidden complaint details, and extracts key information — date, type, status, and complaint body — from all available pages.\n",
    "\n",
    "The resulting dataset offers a window into the struggles families face trying to communicate with incarcerated loved ones and navigate the costly, often unreliable systems that mediate their connection to the outside world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de6cf7db-8465-47bc-a47d-86dff97c66e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.38.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting urllib3<3.0,>=2.5.0 (from urllib3[socks]<3.0,>=2.5.0->selenium)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting trio<1.0,>=0.31.0 (from selenium)\n",
      "  Downloading trio-0.32.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (2025.10.5)\n",
      "Collecting typing_extensions<5.0,>=4.15.0 (from selenium)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.12/site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from webdriver-manager) (24.1)\n",
      "Collecting attrs>=23.2.0 (from trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sortedcontainers in /opt/anaconda3/lib/python3.12/site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from trio<1.0,>=0.31.0->selenium) (3.7)\n",
      "Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/lib/python3.12/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.14.0)\n",
      "Downloading selenium-4.38.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading trio-0.32.0-py3-none-any.whl (512 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: wsproto, urllib3, typing_extensions, attrs, outcome, webdriver-manager, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "Successfully installed attrs-25.4.0 outcome-1.3.0.post0 selenium-4.38.0 trio-0.32.0 trio-websocket-0.12.2 typing_extensions-4.15.0 urllib3-2.5.0 webdriver-manager-4.0.2 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# First things first, let's download Selenium\n",
    "# We use Selenium because the BBB complaints page is dynamically generated with JavaScript, \n",
    "# meaning the complaint data doesn’t appear in the static HTML source. Selenium loads the full\n",
    "# webpage in a real browser session, allowing us to scrape the rendered complaint data accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2eaf40a-9639-47b0-86b5-9f8208779d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=1\n",
      "Found 10 complaints on this page (10 total).\n",
      "Scraping page 2/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=2\n",
      "Found 10 complaints on this page (20 total).\n",
      "Scraping page 3/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=3\n",
      "Found 10 complaints on this page (30 total).\n",
      "Scraping page 4/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=4\n",
      "Found 10 complaints on this page (40 total).\n",
      "Scraping page 5/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=5\n",
      "Found 10 complaints on this page (50 total).\n",
      "Progress saved after page 5.\n",
      "Scraping page 6/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=6\n",
      "Found 10 complaints on this page (60 total).\n",
      "Scraping page 7/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=7\n",
      "Found 10 complaints on this page (70 total).\n",
      "Scraping page 8/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=8\n",
      "Found 10 complaints on this page (80 total).\n",
      "Scraping page 9/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=9\n",
      "Found 10 complaints on this page (90 total).\n",
      "Scraping page 10/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=10\n",
      "Found 10 complaints on this page (100 total).\n",
      "Progress saved after page 10.\n",
      "Scraping page 11/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=11\n",
      "Found 10 complaints on this page (110 total).\n",
      "Scraping page 12/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=12\n",
      "Found 10 complaints on this page (120 total).\n",
      "Scraping page 13/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=13\n",
      "Found 10 complaints on this page (130 total).\n",
      "Scraping page 14/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=14\n",
      "Found 10 complaints on this page (140 total).\n",
      "Scraping page 15/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=15\n",
      "Found 10 complaints on this page (150 total).\n",
      "Progress saved after page 15.\n",
      "Scraping page 16/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=16\n",
      "Found 10 complaints on this page (160 total).\n",
      "Scraping page 17/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=17\n",
      "Found 10 complaints on this page (170 total).\n",
      "Scraping page 18/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=18\n",
      "Found 10 complaints on this page (180 total).\n",
      "Scraping page 19/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=19\n",
      "Found 10 complaints on this page (190 total).\n",
      "Scraping page 20/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=20\n",
      "Found 10 complaints on this page (200 total).\n",
      "Progress saved after page 20.\n",
      "Scraping page 21/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=21\n",
      "Found 10 complaints on this page (210 total).\n",
      "Scraping page 22/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=22\n",
      "Found 10 complaints on this page (220 total).\n",
      "Scraping page 23/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=23\n",
      "Found 10 complaints on this page (230 total).\n",
      "Scraping page 24/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=24\n",
      "Found 10 complaints on this page (240 total).\n",
      "Scraping page 25/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=25\n",
      "Found 10 complaints on this page (250 total).\n",
      "Progress saved after page 25.\n",
      "Scraping page 26/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=26\n",
      "Found 10 complaints on this page (260 total).\n",
      "Scraping page 27/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=27\n",
      "Found 10 complaints on this page (270 total).\n",
      "Scraping page 28/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=28\n",
      "Found 10 complaints on this page (280 total).\n",
      "Scraping page 29/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=29\n",
      "Found 10 complaints on this page (290 total).\n",
      "Scraping page 30/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=30\n",
      "Found 10 complaints on this page (300 total).\n",
      "Progress saved after page 30.\n",
      "Scraping page 31/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=31\n",
      "Found 10 complaints on this page (310 total).\n",
      "Scraping page 32/32: https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=32\n",
      "Found 7 complaints on this page (317 total).\n",
      "\n",
      " Scraping complete! 317 total complaints saved to securus_bbb_complaints_complete.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time, random, traceback\n",
    "\n",
    "## Now let's set up our coding infrastructure \n",
    "\n",
    "BASE_URL = \"https://www.bbb.org/us/tx/carrollton/profile/government-contractors/securus-technologies-llc-0875-41000098/complaints?page=\"\n",
    "HEADLESS = True\n",
    "TOTAL_PAGES = 32\n",
    "OUTPUT_FILE = \"securus_bbb_complaints_complete.csv\"\n",
    "\n",
    "def create_driver():\n",
    "## Launches a fresh Chrome driver with the right options.\"\"\"\n",
    "    options = Options()\n",
    "    if HEADLESS:\n",
    "        options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    options.add_argument(\n",
    "        \"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "driver = create_driver()\n",
    "all_complaints = []\n",
    "\n",
    "## Now let's create a Scraper Loop \n",
    "\n",
    "try:\n",
    "    for page in range(1, TOTAL_PAGES + 1):\n",
    "        try:\n",
    "            url = f\"{BASE_URL}{page}\"\n",
    "            print(f\"Scraping page {page}/{TOTAL_PAGES}: {url}\")\n",
    "            driver.get(url)\n",
    "\n",
    "## Wait for complaint cards to load\n",
    "            wait = WebDriverWait(driver, 30)\n",
    "            wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"li.card.bpr-complaint-grid\")))\n",
    "            time.sleep(random.uniform(2, 4))\n",
    "\n",
    "## Expand “More info” in complaint statuses\n",
    "            detail_buttons = driver.find_elements(By.CSS_SELECTOR, \".bpr-complaint-status details summary\")\n",
    "            for btn in detail_buttons:\n",
    "                try:\n",
    "                    driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                    time.sleep(0.1)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "## Let's parse the HTML with BeautifulSoup\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            cards = soup.select(\"li.card.bpr-complaint-grid\")\n",
    "\n",
    "            for li in cards:\n",
    "                date = li.select_one(\".bpr-complaint-date span\")\n",
    "                ctype = li.select_one(\".bpr-complaint-type span\")\n",
    "                body = li.select_one(\".bpr-complaint-body div\")\n",
    "\n",
    "                # Only take the summary text for status\n",
    "                status_summary = li.select_one(\".bpr-complaint-status summary\")\n",
    "                status = status_summary.get_text(strip=True) if status_summary else None\n",
    "\n",
    "                all_complaints.append({\n",
    "                    \"date\": date.get_text(strip=True) if date else None,\n",
    "                    \"type\": ctype.get_text(strip=True) if ctype else None,\n",
    "                    \"status\": status,\n",
    "                    \"body\": body.get_text(\" \", strip=True) if body else None\n",
    "                })\n",
    "\n",
    "            print(f\"Found {len(cards)} complaints on this page ({len(all_complaints)} total).\")\n",
    "\n",
    "## Save progress every 5 pages\n",
    "            if page % 5 == 0:\n",
    "                pd.DataFrame(all_complaints).to_csv(OUTPUT_FILE, index=False)\n",
    "                print(f\"Progress saved after page {page}.\")\n",
    "\n",
    "## Let's create randomized human-like pauses\n",
    "            time.sleep(random.uniform(3, 7))\n",
    "            if page % 10 == 0:\n",
    "                time.sleep(random.uniform(10, 20))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on page {page}: {e}\")\n",
    "            print(\"Reinitializing browser...\")\n",
    "            driver.quit()\n",
    "            driver = create_driver()\n",
    "            time.sleep(5)\n",
    "            continue  # retry next page\n",
    "\n",
    "## Create our Data Frame and export for use\n",
    "    df = pd.DataFrame(all_complaints)\n",
    "    df.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(f\"\\n Scraping complete! {len(df)} total complaints saved to {OUTPUT_FILE}\")\n",
    "\n",
    "except Exception:\n",
    "    print(\"Fatal error:\\n\")\n",
    "    print(traceback.format_exc())\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf5483d8-1b61-46ba-b3c4-90c18f639fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of scraped data:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>status</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09/22/2025</td>\n",
       "      <td>Service or Repair Issues</td>\n",
       "      <td>UnansweredMore info</td>\n",
       "      <td>My love one calls me and the recording keeps g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09/19/2025</td>\n",
       "      <td>Billing Issues</td>\n",
       "      <td>UnansweredMore info</td>\n",
       "      <td>06-17-2025 &amp; 06-19-2025 I made 2 purchases 1 f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/18/2025</td>\n",
       "      <td>Service or Repair Issues</td>\n",
       "      <td>UnansweredMore info</td>\n",
       "      <td>Endless issue, with message/pictures not being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/15/2025</td>\n",
       "      <td>Product Issues</td>\n",
       "      <td>UnansweredMore info</td>\n",
       "      <td>I am writing to address the problem I am havin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/12/2025</td>\n",
       "      <td>Service or Repair Issues</td>\n",
       "      <td>UnansweredMore info</td>\n",
       "      <td>I, **** ******* #*******, an inmate of Farming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09/09/2025</td>\n",
       "      <td>Service or Repair Issues</td>\n",
       "      <td>UnansweredMore info</td>\n",
       "      <td>Securus had a DATA BREACH affecting the millio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>09/07/2025</td>\n",
       "      <td>Service or Repair Issues</td>\n",
       "      <td>UnansweredMore info</td>\n",
       "      <td>So recently I started getting these spam calls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>09/05/2025</td>\n",
       "      <td>Customer Service Issues</td>\n",
       "      <td>UnansweredMore info</td>\n",
       "      <td>Securus Technologies ******* refused to provid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>08/30/2025</td>\n",
       "      <td>Customer Service Issues</td>\n",
       "      <td>UnansweredMore info</td>\n",
       "      <td>This business has absolutely no Customer Suppo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>08/27/2025</td>\n",
       "      <td>Service or Repair Issues</td>\n",
       "      <td>UnansweredMore info</td>\n",
       "      <td>There is always a problem trying to log in to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                      type               status  \\\n",
       "0  09/22/2025  Service or Repair Issues  UnansweredMore info   \n",
       "1  09/19/2025            Billing Issues  UnansweredMore info   \n",
       "2  09/18/2025  Service or Repair Issues  UnansweredMore info   \n",
       "3  09/15/2025            Product Issues  UnansweredMore info   \n",
       "4  09/12/2025  Service or Repair Issues  UnansweredMore info   \n",
       "5  09/09/2025  Service or Repair Issues  UnansweredMore info   \n",
       "6  09/07/2025  Service or Repair Issues  UnansweredMore info   \n",
       "7  09/05/2025   Customer Service Issues  UnansweredMore info   \n",
       "8  08/30/2025   Customer Service Issues  UnansweredMore info   \n",
       "9  08/27/2025  Service or Repair Issues  UnansweredMore info   \n",
       "\n",
       "                                                body  \n",
       "0  My love one calls me and the recording keeps g...  \n",
       "1  06-17-2025 & 06-19-2025 I made 2 purchases 1 f...  \n",
       "2  Endless issue, with message/pictures not being...  \n",
       "3  I am writing to address the problem I am havin...  \n",
       "4  I, **** ******* #*******, an inmate of Farming...  \n",
       "5  Securus had a DATA BREACH affecting the millio...  \n",
       "6  So recently I started getting these spam calls...  \n",
       "7  Securus Technologies ******* refused to provid...  \n",
       "8  This business has absolutely no Customer Suppo...  \n",
       "9  There is always a problem trying to log in to ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Now, let's display the first 10 rows in a readable format\n",
    "print(\"\\nPreview of scraped data:\\n\")\n",
    "display(df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
